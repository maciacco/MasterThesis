DATA_PATH: "/data/mciacco/LambdaPrompt_PbPb/AnalysisResults_data_TEST_LOW_BACKGROUND.root"
PSEUDODATA_PATH: "/data/mciacco/LambdaPrompt_PbPb/pseudodataFull_TEST_LOW_BACKGROUND.root"
PSEUDODATA_BKG_PATH: "/data/mciacco/LambdaPrompt_PbPb/pseudodataBackground_TEST_LOW_BACKGROUND.root"
BKG_PATH: "/data/mciacco/LambdaPrompt_PbPb/trainingBackground_0_5.root"
ANALYSIS_RESULTS_PATH: "/data/mciacco/LambdaPrompt_PbPb/StrangenessRatios_summary.root"
MC_SIGNAL_PATH: "/data/mciacco/LambdaPrompt_PbPb/trainingSample_reweight_BW_0_5.root"
MC_SIGNAL_RED_PATH: "/data/mciacco/LambdaPrompt_PbPb/mc_cols_rec.root"
MC_SIGNAL_PATH_GEN: "/data/mciacco/LambdaPrompt_PbPb/mc_cols.root"


CT_BINS: [[0,1],[1,2],[2,3],[3,4],[4,5],[5,10]] # training
# CT_BINS_APPLY:  [[[0,0.5,1,1.5,2,2.5,3,3.5,4,4.5,5,6,7,10]]]
# CT_BINS_CENT: [[0,0.5,1,1.5,2,2.5,3,3.5,4,4.5,5,6,7,10],[0,0.5,1,1.5,2,2.5,3,3.5,4,4.5,5,6,7,10],[0,0.5,1,1.5,2,2.5,3,3.5,4,4.5,5,6,7,10]]
CT_BINS_APPLY:  [[[0,1,2,3,4,5,10]]]
CT_BINS_CENT: [[0,1,2,3,4,5,10],[0,1,2,3,4,5,10],[0,1,2,3,4,5,10]]
PT_BINS: [0,0.5,1,1.5,2,2.5,3,3.5,4,4.5,5,5.5,6,6.5,7,7.5,8,8.5,9,9.5,10]  
CENTRALITY_LIST_TRAINING:  [[0, 5]] #, [5,10], [30,50]] # for training
CENTRALITY_LIST:  [[0,5]] #,[5,10],[30,50]]

RANDOM_STATE: 42

HYPERPARAMS:
  n_estimators: 100
  max_depth: 3
  # learning_rate: 0.05
  # gamma: 1
  # learning_rate: 0.0982
  # n_estimators: 181
  seed: 42

HYPERPARAMS_RANGES:
  # booster parameters
  n_estimators: !!python/tuple [300,2000]
  max_depth: !!python/tuple [2,6]
  learning_rate: !!python/tuple [0.05,0.5]
  gamma: !!python/tuple [0.5, 1.5]
  subsample: !!python/tuple [0.5, 0.9]
  colsample_bytree: !!python/tuple [0.5, 0.9]
  # learning_rate: !!python/tuple [0.01, 0.3] # learning rate
  # n_estimators: !!python/tuple [50, 500] # number of boosting trees
  # gamma: !!python/tuple [0.3, 1.1] # specifies the minimum loss reduction required to make a split
  # min_child_weight: !!python/tuple [1, 12]
  # subsample: !!python/tuple [0.5, 0.9] # denotes the fraction of observations to be randomly samples for each tree
  # colsample_bytree: !!python/tuple [0.5, 0.9] # denotes the fraction of columns to be randomly samples for each tree

TRAINING_COLUMNS:
  #- radius #[0,25.4,8]
  #- radiusV0 #[0,25.4,8]
  - dcaBachPV #[0,2.54,8]
  - dcaV0PV #[0,2.54,16]
  - dcaV0piPV #[0,2.54,8]
  - dcaV0prPV #[0,2.54,8]
  - dcaV0tracks #[0,2.54,8]
  - dcaBachV0 #[0,2.54,8]
  - cosPA #[0.95,1,16]
  - cosPAV0 #[0.95,1,16]
  #- V0invMassDelta #[-0.01,0.01,8]
  #- tpcNsigmaBach #[-5,5,8]
  - tpcNsigmaV0Pr #[-5,5,8]
  #- tpcNsigmaV0Pi #[-5,5,8]
  #- competingMass #[0,0.254,8]
  #- bachBarCosPA #[0.9999, 1., 8]
  #- tpcClBach
  #- tpcClV0Pr
  #- tpcClV0Pi