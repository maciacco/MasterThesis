DATA_PATH: "/data/mciacco/LambdaPrompt_PbPb/AnalysisResults_data_TEST_LOW_BACKGROUND.root"
PSEUDODATA_PATH: "/data/mciacco/LambdaPrompt_PbPb/pseudodataFull_TEST_LOW_BACKGROUND.root"
PSEUDODATA_BKG_PATH: "/data/mciacco/LambdaPrompt_PbPb/pseudodataBackground_TEST_LOW_BACKGROUND.root"
BKG_PATH: "/data/mciacco/LambdaPrompt_PbPb/trainingBackground_0_5.root"
ANALYSIS_RESULTS_PATH: "/data/mciacco/LambdaPrompt_PbPb/StrangenessRatios_summary.root"
MC_SIGNAL_PATH: "/data/mciacco/LambdaPrompt_PbPb/trainingSample_reweight_BW_0_5.root"
MC_SIGNAL_RED_PATH: "/data/mciacco/LambdaPrompt_PbPb/mc_cols_rec.root"
MC_SIGNAL_PATH_GEN: "/data/mciacco/LambdaPrompt_PbPb/mc_cols.root"

CT_BINS: [[3, 5], [5,7], [7,10] ,[10,15],[15,20],[20,25],[25,30],[30,40]] # training
CT_BINS_APPLY:  [[[1,1.5,2,2.5,3,3.5,4,4.5,5],[5,5.5,6,6.5,7,7.5,8,8.5,9,9.5,10],[10,10.5,11,11.5,12,12.5,13,13.5,14,14.5,15],[15,15.5,16,16.5,17,17.5,18,18.5,19,19.5,20],[20,20.5,21,21.5,22,22.5,23,23.5,24,24.5,25],[25,25.5,26,26.5,27,27.5,28,28.5,29,29.5,30],[30,30.5,31,31.5,32,32.5,33,33.5,34,34.5,35.5,36,36.5,37,37.5,38,38.5,39,39.5,40]]]
CT_BINS_CENT: [[1,1.5,2,2.5,3,3.5,4,4.5,5,5.5,6,6.5,7,7.5,8,8.5,9,9.5,10,10.5,11,11.5,12,12.5,13,13.5,14,14.5,15,15.5,16,16.5,17,17.5,18,18.5,19,19.5,20,20.5,21,21.5,22,22.5,23,23.5,24,24.5,25,26,27,28,29,30,31,32,33,34,35,36,38,40],[1,1.5,2,2.5,3,3.5,4,4.5,5,5.5,6,6.5,7,7.5,8,8.5,9,9.5,10,10.5,11,11.5,12,12.5,13,13.5,14,14.5,15,15.5,16,16.5,17,17.5,18,18.5,19,19.5,20,20.5,21,21.5,22,22.5,23,23.5,24,24.5,25,26,27,28,29,30,31,32,33,34,35,36,38,40],[1,1.5,2,2.5,3,3.5,4,4.5,5,5.5,6,6.5,7,7.5,8,8.5,9,9.5,10,10.5,11,11.5,12,12.5,13,13.5,14,14.5,15,15.5,16,16.5,17,17.5,18,18.5,19,19.5,20,20.5,21,21.5,22,22.5,23,23.5,24,24.5,25,26,27,28,29,30,31,32,33,34,35,36,38,40]]
PT_BINS: [0,0.5,1,1.5,2,2.5,3,3.5,4,4.5,5,5.5,6,6.5,7,7.5,8,8.5,9,9.5,10]  
CENTRALITY_LIST_TRAINING:  [[0, 5], [5,10], [30,50]] # for training
CENTRALITY_LIST:  [[0,5],[5,10],[30,50]]

RANDOM_STATE: 42

HYPERPARAMS:
  n_estimators: 500
  max_depth: 3
  # learning_rate: 0.05
  # gamma: 1
  # learning_rate: 0.0982
  # n_estimators: 181
  seed: 42

HYPERPARAMS_RANGES:
  # booster parameters
  n_estimators: !!python/tuple [300,2000]
  max_depth: !!python/tuple [2,6]
  learning_rate: !!python/tuple [0.05,0.5]
  gamma: !!python/tuple [0.5, 1.5]
  subsample: !!python/tuple [0.5, 0.9]
  colsample_bytree: !!python/tuple [0.5, 0.9]
  # learning_rate: !!python/tuple [0.01, 0.3] # learning rate
  # n_estimators: !!python/tuple [50, 500] # number of boosting trees
  # gamma: !!python/tuple [0.3, 1.1] # specifies the minimum loss reduction required to make a split
  # min_child_weight: !!python/tuple [1, 12]
  # subsample: !!python/tuple [0.5, 0.9] # denotes the fraction of observations to be randomly samples for each tree
  # colsample_bytree: !!python/tuple [0.5, 0.9] # denotes the fraction of columns to be randomly samples for each tree

TRAINING_COLUMNS:
  - cosPA
  - dcaV0tracks
  - dcaPiPV
  - dcaPrPV
  - dcaV0PV
  - tpcNsigmaPr
  #- tpcNsigmaPi
  #- tpcClV0Pr
  #- tpcClV0Pi
  # - radius
  # - pt
  # - ct
  # - model_output_0